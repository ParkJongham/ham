# 나랑 닮은 연예인은 누구?

## 실습 목표

1.  임베딩에 대해 이해하고 얼굴의 임베딩 벡터를 추출합니다.
2.  얼굴의 임베딩 벡터로 닮은 꼴인 얼굴을 찾습니다.
3.  나와 가까운 연예인을 찾아냅니다.

<br></br>
## 임베딩은 무엇일까?

컴퓨터는 어떻게 다양한 형태의 정보를 표현할 수 있을까?

바로 벡터 공간 (Vector Space) 에 표현하고자 하는 정보를 사상 (Mapping) 하는 방법을 통해 표현한다.

단어이든, 이미지 오브젝트이든 무언가를 벡터로 표현한다면, 그것은 원점에서 출발한 벡터 공간상의 한 점이 되기 때문에 표현하고자 하는 모든 것들은 두 점 사이의 관계를 따지는 것으로 귀결된다.

두 얼굴이 얼마나 닮았는지 구분하는 문제도 두 이미지 간의 벡터 사이의 거리가 얼마나 되는지 구분하는 문제와 같다.

여기 중요한 점은 둘 사이의 유사도를 정확하게 반영해야 한다는 것이다.

두 개의 동일한 크기의 픽셀을 가지는 이미지를 비교한다면 픽셀 수준의 두 이미지 사이의 거리는 0 이 된다.

하지만 픽셀 단위로 구분하고자 한다면 가로 x 세로 100 x 100 픽셀의 컬러 이미지의 경우 3000 차원의 벡터를 비교해야하는 것이다.

이 경우 비교는 사실상 무의미해진다. 너무 높은 차원수의 픽셀 공간에서는 사람이 인지하지 못할만큼 미세한 정보를 담고 있기 때문에 이 고차원에서 측정한 상대적 거리가 유믜미한 유사성이나 차이를 보이는지 확인하기 어렵다.

이러한 문제를 해결하기 위한 방법은 벡터를 더 작은 차원으로 줄여주는 것인데, 고차원 정보를 저차원으로 변환하면서 필요한 정보를 보존하는 것이 바로 임베딩이다.

![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/E-11-3.jpg)
<br></br>
얼굴 이미지의 경우 저차원으로 변환되고, 이 변환된 벡터에 누군지 알아볼 수 있는 정보가 남는다고 가정할 때 임베딩 벡터만으로도 얼굴을 비교할 수 있게된다.

위 그림은 이미지를 128 차원의 얼굴 임베딩 벡터로 변환한 것이다.

임베딩 벡터에 보존되어야하는 필요한 정보란 무엇일까? 

우리는 절대적 의미를 벡터 공간 상에 직접 부여할 수 있는 어떤 정보도 가지고 있지 않으며, 가진 모든 정보는 상대적이다. 이러한 상대적인 정보만을 컴퓨터에게 제공할 수 있는데, 이 정보가 최대한 보존되도록 어떤 오브젝트를 벡터 공간상에 매핑시켜야 그 벡터는 매핑된 오브젝트의 임베딩 역할을 할 수 있게 된다.

+ 참고 : [개요: 머신러닝을 위한 특성 임베딩 추출 및 제공](https://cloud.google.com/solutions/machine-learning/overview-extracting-and-serving-feature-embeddings-for-machine-learning?hl=ko)
<br></br>

임베딩 기법을 활용하여 표현할 수 있는 데이터의 유형에는 뭐가 있을까?

1. 텍스트 (단어, 문장, 전체 문서), 이미지, 오디오 등과 같은 구조화되지 않은 데이터

2. 사용자가 시청한 영화 목록 및 사용자 ID와 같이 상호 작용 컨텍스트만 있고 입력 특성이 없는 항목 

3. 그래프 및 네트워크와 같은 복잡한 구조 데이터. 
	+ 예: 소셜 네트워크 및 생화학 화합물 

4. 텍스트 설명을 사용한 이미지 검색 및 이미지 캡션 작성과 같은 다중 모달 변환 위치 및 점유와 같은 희소 특성(이를 밀집 특성으로 변환) 

5. 인구통계, 사회, 금융, 행동 속성이 300개 이상 포함된 고객 레코드와 같은 고차원 항목(이러한 항목을 보다 간결한 표현으로 변환)위와 같은 많은 종류의 데이터들을 임베딩 기법을 통해 표현 할 수 있으며, 대표적으로 임베딩 기법이 적용된 사례는 유사성 분석, 검색, 기계 전이 학습 등이 있다.

<br></br>
## 얼굴 임베딩 만들기 (01). 얼굴 인식

이미지 속 두 얼굴의 닮은 정도를 알아보기 위해서는 얼굴 임베딩을 구하기 전에 얼굴 영역만을 정확하게 인식해서 추출하는 작업이 필요하다.

이는 비교하고자 하는 정보 외에 불필요한 정보를 배제하기 위해서이다.

![](https://aiffelstaticprd.blob.core.windows.net/media/images/E-11-2.max-800x600.jpg)
<br></br>
얼굴 인식을 위해서는 입력 이미지에 얼굴이 들어있는 사진이 필요하며, 사진에서 얼굴이 어디 있는지를 알아내기 위한 Detection 을 수행한다.

이렇게 얼굴을 찾아내면 얼굴 영역을 잘라내서 (Crop) 딥러닝 네트워크를 거쳐 군집화 (Clustering), 유사도 (Similarity), 분류 (Classification) 등 다양한 Task 에 사용한다.

`dlib` 라는 Face Recognition 라이브러리를 통해 얼굴을 인식할 수 있으며,  `dlib` 라이브러리는 HOG (Histogram of Oriented Gradient) 특성을 사용해 SVM (Support Vector Machine) 의 Sliding Window 로 얼굴을 찾는 Face Detector 기능을 제공한다.

![](https://aiffelstaticprd.blob.core.windows.net/media/images/E-11-11.max-800x600.png)
<br></br>
`dlib` 라이브러리를 통한 얼굴 인식 정확도는 위 그림에서도 알 수 있듯이 99.38 % 에 달하기 때문에 좋은 성능을 기대할 수 있다.

+ 참고 : [Face Recognition GitHub Repository](https://github.com/ageitgey/face_recognition)
<br></br>

> `dlib` 라이브러리 설치
```python
$ pip install cmake 
$ pip install dlib 
$ pip install face_recognition --user
```
<br></br>
> 닮은 얼굴 찾기 실습에 사용할 예제 사진 다운 및 저장
```bash
$ mkdir -p ~/aiffel/face_embedding/images 
$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/biden.jpg 
$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/bush.jpeg 
$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/clinton.jpeg 
$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/obama.jpg 

$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/reagan.jpg 
$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/trump.jpg 
$ mv biden.jpg bush.jpeg clinton.jpeg obama.jpg reagan.jpg trump.jpg ~/aiffel/face_embedding/images
```
- [biden.jpg](https://aiffelstaticprd.blob.core.windows.net/media/documents/biden.jpg)

- [bush.jpeg](https://aiffelstaticprd.blob.core.windows.net/media/documents/bush.jpeg)

- [clinton.jpeg](https://aiffelstaticprd.blob.core.windows.net/media/documents/clinton.jpeg)

- [obama.jpg](https://aiffelstaticprd.blob.core.windows.net/media/documents/obama.jpg)

- [reagan.jpg](https://aiffelstaticprd.blob.core.windows.net/media/documents/reagan.jpg)

- [trump.jpg](https://aiffelstaticprd.blob.core.windows.net/media/documents/trump.jpg)
<br></br>
> 샘플이미지 1 개에서 `face_recognition.face_locations`를 사용해 얼굴 찾기 및 임베딩 추출을 위해 Crop
```python
import face_recognition
import os

image_path = os.getenv('HOME')+'/face_embedding/images/obama.jpg'
image = face_recognition.load_image_file(image_path)
face_locations = face_recognition.face_locations(image)

print(face_locations)  # 이미지에서 얼굴 영역의 좌표를 출력합니다.

%matplotlib inline
import matplotlib.pyplot as plt

a, b, c, d = face_locations[0]
cropped_face = image[a:c,d:b,:]

plt.imshow(cropped_face)   # 이미지에서 얼굴영역만 잘라낸 cropped_face를 그려 봅니다.
```
<br></br>
> 모든 샘플이미지에 `face_recognition.face_locations`를 사용해 얼굴 찾기 및 임베딩 추출을 위해 Crop 적용
```python
import face_recognition
import os

def get_gropped_face(image_file) :
    image = face_recognition.load_image_file(image_file)
    face_locations = face_recognition.face_locations(image)
    a, b, c, d = face_locations[0]
    cropped_face = image[a:c, d:b, :]
      
    return cropped_face
```
<br></br>
> 위 함수가 잘 수행되었는지 확인
```python
image_path = os.getenv('HOME')+'/face_embedding/images/trump.jpg'

cropped_face = get_gropped_face(image_path)
plt.imshow(cropped_face)
```
<br></br>
## 얼굴 임베딩 만들기 (02). FaceNet

![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/E-11-4.png)
<br></br>
FaceNet 은 딥러닝 모델과 크게 다르지 않지만, 네트워크 뒤에 L2 Normalization 을 거쳐 임베딩을 만들어 내고 Triplet Loss 를 사용한다.

L2 Normalization 은 모델 결과물의 L2 Distance 를 구한 후에 이것으로 결과물을 나눠주어 Normalization 을 해주는 과정이다. 

L2 Normalization 레이어를 거쳐나온 임베딩 벡터는 벡터의 크기가 1 로 맞춰지게 되므로 128 차원의 공간상에 반지름이 1 인 구가 있다고 할 때, 구의 표면상의 한 점을 가리키는 벡터처럼 분포된다. 

이렇게 제약조건을 주어 두 점 사이의 거리를 계산할 때 두 벡터의 절대적 크기에 무관하게 두 벡터 사이의 각도에만 영향을 받게된다.
<br></br>
![](https://aiffelstaticprd.blob.core.windows.net/media/images/E-11-5.max-800x600.png)
<br></br>
Triplet Loss 란 세 개의 데이터 쌍을 이용해 계산하는 손실함수로 네트워크를 학습 시킬 수 있다.

임베딩 안에 보존되어야 할 정보는 상대적인 비교 수치 (A 는 B 에 비해 C 에 더 가깝다.) 밖에 없으며, Triplet Loss 개념은 이를 반영한 기법이다.

사람 얼굴 데이터 셋에서 A 와 C 는 같은 사람의 얼굴 사진에서 나온 임베딩 벡터, B 는 다른 사람의 얼굴 사진에서 만들어진 임베딩 벡터가 되도록 데이터셋을 구성한다.

이때 A 는 B 에 비해 C 에 더 가깝다 라는 논리가 성립해야만한다. Triplet Loss 는 같은 사람은 이 임베딩 벡터 A - C 간의 거리를 가깝게 그리고 다른 사람의 임베딩 벡터 B - C 간의 거리를 멀게 학습을 시키는 효과를 가져온다.

위 그림과 같이 사람의 얼굴에서 나온 임베딩이 멀리 배치된다면 학습을 통해 가까워지도록 임베딩 벡터를 만들어 내는 것이다.

+ 참고 : 
	+ [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/abs/1503.03832)
	+ [Triplet Loss 영상](https://www.youtube.com/watch?v=d2XB5-tuCWU) 
<br></br>
`Face Recognition` 에는 `FaceNet` 얼굴 임베딩 모델이 탑재되어 있다.
> 샘플 이지미에서 얼굴 임베딩 추출
```python
import os

dir_path = os.getenv('HOME')+'/face_embedding/images'
file_list = os.listdir(dir_path)

print ("file_list: {}".format(file_list))
```
<br></br>
> `Face Recognition` 패키지에서 제공하는 얼굴 임베딩 벡터를 구하는 `face_recognition.face_encodings()` 함수 를 활용해 얼굴 영역의 임베딩 벡터 구하기
```python
image_file = os.path.join(dir_path, 'obama.jpg')
face = get_gropped_face(image_file)   # 얼굴 영역을 구하는 함수(이전 스텝에서 구현)

# 얼굴 영역을 가지고 얼굴 임베딩 벡터를 구하는 함수
def get_face_embedding(face):
    return face_recognition.face_encodings(face)

embedding = get_face_embedding(face)  
embedding
```
<br></br>
> `images` 디렉토리 안에 있는 모든 이미지 파일의 임베딩을 구해서 `dict` 구조에 담아 리턴하는 함수 생성
> 딕셔너리의 각 엘리먼트는 `사람 이름:임베딩벡터`로 하며, 함수 이름은 `get_face_embedding_dict(dir_path)`이고, 다음과 같이 사용한다.
```python
def get_face_embedding_dict(dir_path) : 
    file_list = os.listdir(dir_path)
    embedding_dict = {}
    
    for file in file_list : 
        img_path = os.path.join(dir_path, file)
        face = get_gropped_face(img_path)
        embedding = get_face_embedding(face)
        
        # 얼굴영역 face 가 제대로 detect 되지 않으면
        # len(embedding) == 0 인 경우가 발생하므로
        # os.path.splitext(file)[0] 에는
        # 이미지 파일명에서 확장자를 제거한 이름이 담긴다.
        if len(embedding) >  0 :
            embedding_dict[os.path.splitext(file)[0]] = embedding[0]
    
    return embedding_dict
```
<br></br>
> `get_face_embedding_dict()` 함수가 잘 만들어졌는지 확인
```python
embedding_dict = get_face_embedding_dict(dir_path)
embedding_dict['trump']
```
<br></br>
## 얼굴 임베딩 사이의 거리 측정

Triplet Loss 는 같은 사람의 얼굴 쌍을 임베딩 공간 상에서 가깝도록 그리고 다른 사람의 얼굴 쌍을 멀도록 학습시킨다.

이를 활용해 학습된 모델에서는 임베딩 공간에서 서로 다른 사람이라면 임베딩 거리가 멀게 표현된다. 즉, 임베딩 거리가 가까운 사람은 닮은 사람일 확률이 높고 먼 사람은 다른 서로 다른 사람일 확률이 높은 것이다.

  > 위에서 생선한 모델을 통해 임베딩 간 거리 확보 여부 확인
```python
import numpy as np

A = np.array([0.0019173615146428347, 0.17689529061317444, 0.0763588473200798, -0.024574430659413338, -0.13141091167926788, 0.0344821996986866, -0.0374063216149807, -0.07056370377540588, 0.048655178397893906, -0.03414120525121689, 0.22696012258529663, -0.061402369290590286, -0.24329672753810883, -0.039421431720256805, 0.0621466189622879, 0.1220191940665245, -0.1616966724395752, -0.06176016479730606, -0.18894734978675842, -0.06051916256546974, -0.010404378175735474, -0.05918719246983528, 0.02205268107354641, -0.06932859122753143, -0.20260301232337952, -0.2425234317779541, -0.04454419016838074, -0.11400106549263, -0.02022719383239746, -0.15134216845035553, 0.07622595876455307, -0.0323314443230629, -0.1404413878917694, -0.056338660418987274, -0.04520038887858391, -0.026131991297006607, -0.0352761372923851, -0.0679447203874588, 0.1318240910768509, 0.034210119396448135, -0.17475582659244537, 0.13853909075260162, -0.0027398746460676193, 0.227312833070755, 0.3029572069644928, 0.004932125099003315, 0.05853061378002167, -0.07521739602088928, 0.1443275809288025, -0.2340908795595169, 0.030092637985944748, 0.040133409202098846, 0.1672351360321045, 0.05728958174586296, 0.11475440859794617, -0.07548368722200394, 0.040267568081617355, 0.16487033665180206, -0.21067440509796143, 0.036163005977869034, 0.051559075713157654, -0.05994952470064163, 0.029524143785238266, -0.04122130945324898, 0.13074155151844025, 0.1142958477139473, -0.00561982998624444, -0.09740489721298218, 0.18533651530742645, -0.10422169417142868, -0.11409182846546173, 0.02283927984535694, -0.08339140564203262, -0.13673236966133118, -0.3275497853755951, -0.0002689119428396225, 0.2842463254928589, 0.13883619010448456, -0.29149484634399414, -0.07276060432195663, -0.03179163485765457, 0.011192545294761658, 0.03802505508065224, 0.03392524644732475, -0.03972085565328598, -0.12013585865497589, -0.06272879987955093, -0.026893358677625656, 0.2430601865053177, -0.12022019177675247, -0.010466678068041801, 0.20199882984161377, 0.051095910370349884, -0.13243277370929718, 0.06056740880012512, -0.04802423343062401, -0.12318279594182968, -0.013157366774976254, -0.12076889723539352, -0.07183175534009933, -0.01982908323407173, -0.15032584965229034, -0.026652328670024872, 0.06820419430732727, -0.24668177962303162, 0.1818322390317917, -0.01959969662129879, -0.07208395004272461, -0.0680316612124443, -0.038368165493011475, 0.021410271525382996, 0.06388168036937714, 0.2293335199356079, -0.22541724145412445, 0.19133104383945465, 0.24343697726726532, -0.04034627974033356, 0.07534503191709518, 0.017645064741373062, 0.054646339267492294, -0.046512290835380554, 0.07076910138130188, -0.0960201621055603, -0.12610889971256256, -0.017934376373887062, -0.010262779891490936, 0.01885927841067314, 0.057148948311805725])

B = np.array([-0.08116298168897629, 0.1283080279827118, 0.024102725088596344, -0.03748808428645134, 0.06578215956687927, -0.07137967646121979, -0.10578329861164093, -0.0911930501461029, 0.19589228928089142, -0.09603863954544067, 0.2447616308927536, 0.07736924290657043, -0.17048686742782593, -0.1277867704629898, 0.06390697509050369, 0.12272421270608902, -0.19242052733898163, -0.08341517299413681, -0.11065894365310669, -0.09501136839389801, -0.010332206264138222, -0.008188878186047077, 0.08251037448644638, 0.04358505830168724, -0.1455313265323639, -0.3595622479915619, -0.07877802848815918, -0.18927346169948578, -0.0018955999985337257, -0.06280332803726196, -0.06073163449764252, 0.03181075677275658, -0.15109844505786896, -0.08682074397802353, 0.017340943217277527, -0.020879391580820084, 0.008258359506726265, 0.016738882288336754, 0.16803768277168274, 0.039162665605545044, -0.09613757580518723, 0.06231086328625679, 0.00924085732549429, 0.2418847680091858, 0.26051488518714905, 0.07355985790491104, 0.05239278823137283, -0.08052310347557068, 0.08884726464748383, -0.24261267483234406, 0.05618546903133392, 0.12175332009792328, 0.09056758135557175, 0.04266638681292534, 0.16591356694698334, -0.2005864679813385, 0.01018378883600235, 0.08819808065891266, -0.15550008416175842, 0.0815843716263771, 0.03018287755548954, -0.025435002520680428, -0.06714558601379395, 0.009693139232695103, 0.22243273258209229, 0.13470745086669922, -0.1363328993320465, 0.01635543815791607, 0.18212205171585083, -0.03392908349633217, 0.0398673489689827, 0.0043264636769890785, -0.15493592619895935, -0.2530894875526428, -0.23155181109905243, 0.0678660124540329, 0.31580865383148193, 0.21846994757652283, -0.20842058956623077, 0.012199334800243378, -0.12194785475730896, 0.059383176267147064, 0.0768171101808548, -0.012840969488024712, -0.11975857615470886, -0.11892750859260559, -0.03087366186082363, 0.04432998597621918, 0.09186872839927673, 0.0821407362818718, -0.018520792946219444, 0.1962793618440628, -0.0566205158829689, 0.026071354746818542, 0.007139421068131924, 0.02185123600065708, -0.11292634904384613, -0.044381096959114075, -0.18024618923664093, -0.007845945656299591, 0.010368190705776215, -0.07480168342590332, -0.0035089245066046715, 0.09972234815359116, -0.18773995339870453, 0.0474785715341568, 0.025760797783732414, -0.042169712483882904, 0.0014017894864082336, 0.1201503798365593, -0.05088714882731438, -0.02051539719104767, 0.0884844958782196, -0.2176845818758011, 0.25695914030075073, 0.23358485102653503, 0.019985560327768326, 0.17838242650032043, 0.029055196791887283, 0.04518195986747742, -0.044122979044914246, -0.043431997299194336, -0.15906637907028198, -0.07155231386423111, 0.02525237947702408, 0.02502967044711113, 0.04127159342169762, 0.011846683919429779])

C = np.array([-0.0762145072221756, 0.09951083362102509, 0.0012626983225345612, -0.05529194697737694, -0.006535547785460949, -0.012212716042995453, -0.07667708396911621, -0.07388101518154144, 0.18756520748138428, -0.07589773088693619, 0.2424328476190567, 0.06438330560922623, -0.22197730839252472, -0.13409815728664398, 0.046808283776044846, 0.14692817628383636, -0.1844339370727539, -0.051137253642082214, -0.1149090975522995, -0.1297808736562729, 0.040612753480672836, -0.002555673476308584, 0.10426937788724899, 0.026295233517885208, -0.13127824664115906, -0.35947439074516296, -0.048153407871723175, -0.17165206372737885, -0.0002263905480504036, -0.10254599899053574, -0.08338439464569092, 0.014203382655978203, -0.18179851770401, -0.13200539350509644, 0.03813670203089714, -0.012789442203938961, -0.0030085663311183453, -0.007307708729058504, 0.17558619379997253, 0.025768719613552094, -0.12877899408340454, 0.11051110923290253, 0.03616628795862198, 0.22539083659648895, 0.2838597595691681, 0.07483825087547302, -0.0036694444715976715, -0.09967216849327087, 0.11106447875499725, -0.22961333394050598, 0.06397823244333267, 0.12394970655441284, 0.06568531692028046, 0.037825535982847214, 0.09586739540100098, -0.18721607327461243, 0.01674063131213188, 0.10057111084461212, -0.15766742825508118, 0.008397659286856651, 0.039109550416469574, -0.06041106954216957, -0.046033550053834915, 0.031240269541740417, 0.2121172845363617, 0.103468157351017, -0.1224282756447792, -0.05559460073709488, 0.12153220176696777, -0.018480442464351654, 0.039875734597444534, 0.007489997893571854, -0.18950346112251282, -0.20904967188835144, -0.23732705414295197, 0.0895664244890213, 0.3778454661369324, 0.16606193780899048, -0.20442475378513336, 0.018602905794978142, -0.18367978930473328, 0.04945264756679535, 0.08889186382293701, 0.002995049115270376, -0.06196683272719383, -0.13028381764888763, -0.03548961132764816, 0.053789377212524414, 0.08386979252099991, 0.016627438366413116, -0.040179431438446045, 0.2289249151945114, -0.02149147540330887, 0.05046383664011955, 0.02314644865691662, 0.05424635857343674, -0.1627081036567688, -0.01140156015753746, -0.18031321465969086, -0.06785157322883606, 0.03336677327752113, -0.06467186659574509, 0.0466950424015522, 0.12832939624786377, -0.2377130389213562, 0.06774994730949402, 0.013810726813971996, -0.019034255295991898, 0.04477768391370773, 0.0660984218120575, -0.031004268676042557, -0.03275192156434059, 0.06632497161626816, -0.24120087921619415, 0.2647172510623932, 0.2477877289056778, 0.054315339773893356, 0.17328208684921265, 0.06950142979621887, 0.019016757607460022, -0.01211759727448225, -0.014044362120330334, -0.17701464891433716, -0.03347969055175781, 0.04914966598153114, 0.05660251900553703, 0.0644666999578476, 0.012375651858747005])
```
<br></br>
![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/E-11-9.png)
<br></br>
각 128 차원의 벡터는 넘파이 (Numpy)  연산을 하기 위해서 리스트(list)에서 넘파이 배열 (Numpy Array) 로 변환하고 각 벡터간의 거리를 `numpy.linalg.norm` 를 활용하여 L2 Norm Distance 로 계산한다.

L2 Norm Distance 는 위의 식처럼 각 차원의 차이를 제곱한 뒤 합한 후 제곱근을 구한 값이다. 2차원 유클리디안 거리를 다차원으로 확장시킨 것이다.

> L2 Norm Distance 계산
```python
distances = np.linalg.norm([A, B] - C, axis=1, ord=2)
print("Distance between A and C: {}".format(distances[0]))
print("Distance between B and C: {}".format(distances[1]))
```
같은 사람인 B 와 C 의 거리는 0.3474 로 다른 사람 간의 거리 (A 와 C) 인 0.8212 보다 상대적으로 작은 것을 볼 수 있다.
<br></br>
이렇게 임베딩으로 사람 얼굴을 비교하고 누가 같은 사람인지 비교할 수 있다.

만약 L2 Distance 대신 L1 Distance 로 계산한다면 전체적인 Distance 값의 분포가 커진다.

> L2 Distance 대신 L1 Distance 를 이용한 거리 계산
```python
distances = np.linalg.norm([A, B] - C, axis=1, ord=1)
print("Distance between A and C: {}".format(distances[0]))
print("Distance between B and C: {}".format(distances[1]))
```
<br></br>
> `np.linalg.norm`에서 L1 distance 와 L2 distance 계산방식
```python
import numpy as np

x = np.array([1,2,3,4,5])
y = np.array([2,3,4,5,6])

print(np.linalg.norm(y-x, ord=1))  #L1 distance
print(np.linalg.norm(y-x, ord=2))  #L2 distance
```
<br></br>
> 두 임베딩 벡터간 거리를 계산하는 함수 구현
> (`np.linalg.norm`를 활용)
```python
def get_distance(name1, name2):
    return np.linalg.norm(embedding_dict[name1]-embedding_dict[name2], ord=2)

get_distance('obama', 'trump')
```
<br></br>
## 얼굴임베딩 공간의 시각화

임베딩 벡터를 넘파이로 볼 때 사람의 눈으로 가까운지 먼지 가늠하기 어렵다.

이렇게 고차원 데이터를 저차원으로 바꾼 임베딩처럼 다차원 벡터를 시각화 하기 위해서는 차원 축소를 하는 방법들이 있다.

Tensorflow 의 `Projector` 는 고차원 벡터를 차원 축소 기법을 사용해서 눈으로 확인할 수 있게 해준다.

+ 참고 : [128D FaceNet LFW Embedding Visualization](https://huyhoang17.github.io/128D-Facenet-LFW-Embedding-Visualisation/)
<br></br>
![](https://aiffelstaticprd.blob.core.windows.net/media/images/E-11-10.max-800x600.png)
<br></br>
PCA 와 T-SNE 를 이용해 우리가 쉽게 볼 수 있는 형태로 차원을 축소할 수 있다.

- 먼저 PCA 는 주성분 분석이라는 방법으로 Principal Component Analysis 의 준말로 이 방법은 모든 차원의 축에 따른 값의 변화도인 분산 (Variance) 을 확인한 뒤 그 중 변화가 가장 큰 주요한 축을 남기는 방법이다.

- T-SNE 는 고차원 상에서 먼 거리를 저차원 상에서도 멀리 배치되도록 차원을 축소하는 방식으로, 먼저 random하게 목표하는 차원에 데이터들을 배치한 후 각 데이터들을 고차원 상에서의 배치와 비교를 하면서 위치를 변경해 주는 알고리즘이다.

위 시각화 그림에서 볼 수 있듯이 PCA 에서는 모든 차원이 잘 반영되지 않으며, 반면에 T - SEN 는 Iteration 을 거칠수록 가까운 벡터들이 잘 군집한 형태로 차원 축소가 되는 것을 볼 수 있다.

+ 참고 : 
	 -   PCA:  [차원 감소와 PCA 분석](https://bcho.tistory.com/1209?category=555440)
	-   T-SNE:  [(영상) StatQuest: t-SNE, Clearly Explained](https://www.youtube.com/watch?v=NEaUSP4YerM)
<br></br>
## 가장 닮은 꼴 얼굴 찾아보기

앞서 구현한 함수는 다음과 같다.

-   `def get_gropped_face(image_file)`  : 이미지 파일에서 얼굴 영역을 가져오는 함수

-   `def get_face_embedding(face)`  : 얼굴영역으로부터 얼굴 임베딩 벡터를 구하는 함수

-   `def get_face_embedding_dict(dir_path)`  : 디렉토리 안에 있는 모든 이미지의 임베딩 딕셔너리를 구하는 함수

-   `def get_distance(name1, name2)`  : 두 이미지(사람 이름) 사이의 임베딩 벡터 거리를 구하는 함수
<br></br>

이제 특정 이미지와 가장 닮은 이미지를 구하는 기능을 수행하는 함수를  만들어보자.

이 함수는 `name` 인자에 특정 사람 이름을 주면 그 사람과 가장 닮은 이미지와 거리 정보를 가장 가까운 순으로 정렬해서 표시해줘야한다.
<br></br>
> 특정 이미지와 가장 닮은 이미지를 구하는 기능을 수행하는 함수 서식
```python
def get_nearest_face(name, top=5): 
	....... get_nearest_face('trump') 
	>> 수행결과 
	순위 1 : 이름(biden), 거리(0.682061661275583) 
	순위 2 : 이름(clinton), 거리(0.6875851008652103) 
	순위 3 : ... 
	(이하생략)
```
<br></br>
> 특정 이미지와 가장 닮은 이미지를 구하는 기능을 수행하는 함수 구현
```python
# name1과 name2의 거리를 비교하는 함수를 생성하되, name1은 미리 지정하고, name2는 호출시에 인자로 받도록 합니다.
def get_sort_key_func(name1):
    def get_distance_from_name1(name2):
        return get_distance(name1, name2)
    return get_distance_from_name1

sort_key_func = get_sort_key_func('trump')   
# 이렇게 생성된 함수 sort_key_func는 sort_key_func('obama') 라고 호출할 때 trump와 obama 사이의 임베딩 벡터 거리를 계산합니다.
```
<br></br>
> 얼굴 임베딩 딕셔너리를 오름차순 정렬하되, 정렬 기준을 특정 인물 사진과의 임베딩 벡터 거리 함수로 정렬
```python
sorted(embedding_dict.items(), key=lambda x:sort_key_func(x[0]))
```
<br></br>
> 입력받은 임의의 이름에 대해 다른 이미지의 임베딩 거리를 정렬해서 적절히 출력
```python
def get_nearest_face(name, top=5):
    sort_key_func = get_sort_key_func(name)
    sorted_faces = sorted(embedding_dict.items(), key=lambda x:sort_key_func(x[0]))

    for i in range(top+1):
        if i == 0 :   # 첫번째로 나오는 이름은 자기 자신일 것이므로 제외합시다. 
            continue
        if sorted_faces[i]:
            print('순위 {} : 이름({}), 거리({})'.format(i, sorted_faces[i][0], sort_key_func(sorted_faces[i][0])))
```
<br></br>
> 닮은 사람 찾기
```python
# obama와 가장 닮은 사람은 누굴까요?
get_nearest_face('obama')
```
<br></br>

